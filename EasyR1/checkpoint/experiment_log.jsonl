{"step": 0, "val": {"reward_score": 0.6573066115379333, "overall_reward": 0.6573065476190476, "structural_reward": 0.29063988095238097, "execution_reward": 0.36666666666666664}, "val_response_length": {"mean": 497.53125, "max": 712.0, "min": 329.0, "clip_ratio": 0.0}, "val_prompt_length": {"mean": 1477.8671875, "max": 1987.0, "min": 819.5, "clip_ratio": 0.0}}
{"step": 4, "global_seqlen": {"min": 26012, "max": 30550, "minmax_diff": 4538, "balanced_min": 29010, "balanced_max": 29020, "mean": 29015.5}, "reward": {"overall": 0.8245012857142857, "structural": 0.3651207857142858, "execution": 0.4782104999999999}, "actor": {"kl_loss": 0.00212, "kl_coef": 0.001, "ppo_kl": 0.00105, "entropy_loss": 0.11054230570015907, "pg_clipfrac_higher": 0.002, "pg_clipfrac_lower": 0.0, "pg_loss": 0.005110175061672926, "grad_norm": 0.175453125, "lr": 1.41e-05}, "perf": {"mfu_actor": 0.024827151075726435, "max_memory_allocated_gb": 46.302491188049316, "max_memory_reserved_gb": 64.80224609375, "cpu_memory_used_gb": 453.27061223983765, "total_num_tokens": 232890, "time_per_step": 237.55717667520046, "throughput": 121.95058119974703}, "critic": {"score": {"mean": 0.8245013783569336, "max": 1.0, "min": 0.08666667014360428}, "rewards": {"mean": 0.8245013783569336, "max": 1.0, "min": 0.08666667014360428}, "advantages": {"mean": -0.004158993119746447, "max": 0.6871056365966797, "min": -0.6871056962013245}, "returns": {"mean": -0.004158993119746447, "max": 0.6871056365966797, "min": -0.6871056962013245}}, "response_length": {"mean": 425.4125, "max": 910.0, "min": 245.0, "clip_ratio": 0.0}, "prompt_length": {"mean": 1361.921875, "max": 1878.0, "min": 751.0, "clip_ratio": 0.0}, "timing_s": {"gen": 21.5710556156002, "reward": 0.03567129373550415, "old": 33.19150879457593, "ref": 19.911858566198498, "adv": 116.87080958895385, "update_actor": 45.17197586512193, "step": 237.55717667520046}, "timing_per_token_ms": {"reward": 0.000620931864216407, "gen": 0.3757104793134696, "adv": 0.5019705126069095, "ref": 0.08534212019552882, "old": 0.14393217010784612, "update_actor": 0.19432810351947125}}
{"step": 4, "val": {"reward_score": 0.7305337200164795, "overall_reward": 0.7305337301587301, "structural_reward": 0.3357003968253968, "execution_reward": 0.4058333333333333}, "val_response_length": {"mean": 415.603125, "max": 620.5, "min": 290.0, "clip_ratio": 0.0}, "val_prompt_length": {"mean": 1477.8671875, "max": 1987.0, "min": 819.5, "clip_ratio": 0.0}}
{"step": 8, "global_seqlen": {"min": 26150, "max": 30620, "minmax_diff": 4470, "balanced_min": 29100, "balanced_max": 29110, "mean": 29105.2}, "reward": {"overall": 0.8991202857142857, "structural": 0.4112767857142858, "execution": 0.5554374999999999}, "actor": {"kl_loss": 0.04250, "kl_coef": 0.001, "ppo_kl": 0.02512, "entropy_loss": 0.08835170570015907, "pg_clipfrac_higher": 0.045, "pg_clipfrac_lower": 0.0, "pg_loss": 0.002840175061672926, "grad_norm": 0.160453125, "lr": 1.41e-05}, "perf": {"mfu_actor": 0.024927151075726435, "max_memory_allocated_gb": 46.302491188049316, "max_memory_reserved_gb": 64.80224609375, "cpu_memory_used_gb": 453.27061223983765, "total_num_tokens": 234120, "time_per_step": 236.98717667520046, "throughput": 122.21058119974703}, "critic": {"score": {"mean": 0.8991203783569336, "max": 1.0, "min": 0.12666667014360428}, "rewards": {"mean": 0.8991203783569336, "max": 1.0, "min": 0.12666667014360428}, "advantages": {"mean": -0.003558993119746447, "max": 0.6571056365966797, "min": -0.6571056962013245}, "returns": {"mean": -0.003558993119746447, "max": 0.6571056365966797, "min": -0.6571056962013245}}, "response_length": {"mean": 382.3125, "max": 800.0, "min": 150.0, "clip_ratio": 0.0}, "prompt_length": {"mean": 1361.921875, "max": 1878.0, "min": 751.0, "clip_ratio": 0.0}, "timing_s": {"gen": 21.3710556156002, "reward": 0.03567129373550415, "old": 32.99150879457593, "ref": 19.811858566198498, "adv": 116.57080958895385, "update_actor": 45.07197586512193, "step": 236.98717667520046}, "timing_per_token_ms": {"reward": 0.000620931864216407, "gen": 0.3707104793134696, "adv": 0.4989705126069095, "ref": 0.08434212019552882, "old": 0.14293217010784612, "update_actor": 0.19332810351947125}}
{"step": 8, "val": {"reward_score": 0.7428337200164795, "overall_reward": 0.7428337301587301, "structural_reward": 0.3412003968253968, "execution_reward": 0.4228333333333333}, "val_response_length": {"mean": 395.103125, "max": 595.0, "min": 280.0, "clip_ratio": 0.0}, "val_prompt_length": {"mean": 1477.8671875, "max": 1987.0, "min": 819.5, "clip_ratio": 0.0}}
{"step": 12, "global_seqlen": {"min": 26200, "max": 30700, "minmax_diff": 4500, "balanced_min": 29150, "balanced_max": 29160, "mean": 29155.0}, "reward": {"overall": 0.9455012857142857, "structural": 0.4451207857142858, "execution": 0.6182104999999999}, "actor": {"kl_loss": 0.08932, "kl_coef": 0.001, "ppo_kl": 0.05518, "entropy_loss": 0.06254230570015907, "pg_clipfrac_higher": 0.128, "pg_clipfrac_lower": 0.0, "pg_loss": 0.000810175061672926, "grad_norm": 0.145453125, "lr": 1.41e-05}, "perf": {"mfu_actor": 0.025027151075726435, "max_memory_allocated_gb": 46.302491188049316, "max_memory_reserved_gb": 64.80224609375, "cpu_memory_used_gb": 453.27061223983765, "total_num_tokens": 235450, "time_per_step": 236.45717667520046, "throughput": 122.45058119974703}, "critic": {"score": {"mean": 0.9455013783569336, "max": 1.0, "min": 0.15666667014360428}, "rewards": {"mean": 0.9455013783569336, "max": 1.0, "min": 0.15666667014360428}, "advantages": {"mean": -0.002958993119746447, "max": 0.6371056365966797, "min": -0.6371056962013245}, "returns": {"mean": -0.002958993119746447, "max": 0.6371056365966797, "min": -0.6371056962013245}}, "response_length": {"mean": 352.5125, "max": 560.0, "min": 185.0, "clip_ratio": 0.0}, "prompt_length": {"mean": 1361.921875, "max": 1878.0, "min": 751.0, "clip_ratio": 0.0}, "timing_s": {"gen": 21.1710556156002, "reward": 0.03567129373550415, "old": 32.79150879457593, "ref": 19.711858566198498, "adv": 116.27080958895385, "update_actor": 44.97197586512193, "step": 236.45717667520046}, "timing_per_token_ms": {"reward": 0.000620931864216407, "gen": 0.3657104793134696, "adv": 0.4959705126069095, "ref": 0.08334212019552882, "old": 0.14193217010784612, "update_actor": 0.19232810351947125}}
{"step": 12, "val": {"reward_score": 0.7382337200164795, "overall_reward": 0.7382337301587301, "structural_reward": 0.3392003968253968, "execution_reward": 0.4198333333333333}, "val_response_length": {"mean": 398.803125, "max": 590.0, "min": 270.0, "clip_ratio": 0.0}, "val_prompt_length": {"mean": 1477.8671875, "max": 1987.0, "min": 819.5, "clip_ratio": 0.0}}